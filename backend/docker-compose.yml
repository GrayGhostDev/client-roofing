version: '3.8'

services:
  # =============================================================================
  # Backend API Service
  # =============================================================================
  backend:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: iswitch-crm-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - FLASK_ENV=production
      - FLASK_DEBUG=False
      - HOST=0.0.0.0
      - PORT=8000
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=${SECRET_KEY}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - PUSHER_APP_ID=${PUSHER_APP_ID}
      - PUSHER_KEY=${PUSHER_KEY}
      - PUSHER_SECRET=${PUSHER_SECRET}
      - PUSHER_CLUSTER=${PUSHER_CLUSTER}
      - SENDGRID_API_KEY=${SENDGRID_API_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:8501}
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - iswitch-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # =============================================================================
  # Redis Cache Service
  # =============================================================================
  redis:
    image: redis:7-alpine
    container_name: iswitch-crm-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - iswitch-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s

  # =============================================================================
  # Frontend Dashboard Service (Streamlit)
  # =============================================================================
  frontend:
    build:
      context: ../frontend-streamlit
      dockerfile: Dockerfile
    container_name: iswitch-crm-frontend
    restart: unless-stopped
    ports:
      - "8501:8501"
    environment:
      - BACKEND_URL=http://backend:8000
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_ENABLE_CORS=false
      - STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION=true
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - iswitch-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # =============================================================================
  # Nginx Reverse Proxy (Optional - for production SSL termination)
  # =============================================================================
  nginx:
    image: nginx:alpine
    container_name: iswitch-crm-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - backend
      - frontend
    networks:
      - iswitch-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # Celery Worker (Optional - for background jobs)
  # =============================================================================
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: iswitch-crm-celery-worker
    restart: unless-stopped
    command: celery -A app.celery worker --loglevel=info --concurrency=4
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=${SECRET_KEY}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - SENDGRID_API_KEY=${SENDGRID_API_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
    volumes:
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - iswitch-network

  # =============================================================================
  # Celery Beat Scheduler (Optional - for periodic tasks)
  # =============================================================================
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: iswitch-crm-celery-beat
    restart: unless-stopped
    command: celery -A app.celery beat --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
      celery-worker:
        condition: service_started
    networks:
      - iswitch-network

# =============================================================================
# Networks
# =============================================================================
networks:
  iswitch-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# =============================================================================
# Volumes
# =============================================================================
volumes:
  redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/redis

# =============================================================================
# Usage Instructions
# =============================================================================
#
# 1. Basic startup (backend + redis + frontend):
#    docker-compose up -d backend redis frontend
#
# 2. Full stack with nginx and celery:
#    docker-compose up -d
#
# 3. View logs:
#    docker-compose logs -f backend
#    docker-compose logs -f frontend
#
# 4. Stop all services:
#    docker-compose down
#
# 5. Stop and remove volumes (careful - deletes data):
#    docker-compose down -v
#
# 6. Rebuild containers after code changes:
#    docker-compose build
#    docker-compose up -d
#
# 7. Scale celery workers:
#    docker-compose up -d --scale celery-worker=4
#
# 8. Check service health:
#    docker-compose ps
#    curl http://localhost:8000/health
#    curl http://localhost:8501/_stcore/health
#
# 9. Execute commands in running containers:
#    docker-compose exec backend python scripts/seed_data.py
#    docker-compose exec backend flask shell
#
# 10. Monitor resource usage:
#     docker stats
#
# =============================================================================
# Production Deployment Checklist
# =============================================================================
#
# [ ] Copy .env.production to .env and update all secrets
# [ ] Create ./data/redis directory: mkdir -p ./data/redis
# [ ] Create ./uploads directory: mkdir -p ./uploads
# [ ] Create ./logs directory: mkdir -p ./logs
# [ ] Create ./nginx/ssl directory with SSL certificates
# [ ] Update nginx.conf with your domain
# [ ] Run database migrations: docker-compose exec backend flask db upgrade
# [ ] Seed initial data (if needed): docker-compose exec backend python scripts/seed_data.py
# [ ] Test health endpoints
# [ ] Configure firewall to allow ports 80, 443
# [ ] Setup log rotation for ./logs directory
# [ ] Configure backup strategy for redis data
# [ ] Setup monitoring and alerting
# [ ] Test SSL certificate auto-renewal
#
# =============================================================================
